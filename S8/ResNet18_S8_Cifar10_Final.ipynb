{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "ResNet18_S8_Cifar10_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbdg0z4poCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision \n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QopPSFSZoLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes \n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5lkU3NAvSFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f9ff965-2faa-40f6-f6ba-7b7c6a033f4a"
      },
      "source": [
        "m = [125.30691805, 122.95039414, 113.86538318]\n",
        "m = tuple([x/255 for x in m])\n",
        "m"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.49139967862745093, 0.48215840839215685, 0.44653091443137255)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShNnXzCfvSqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b6019ff-a4b0-422d-b982-013f52cc9afe"
      },
      "source": [
        "s = [62.99321928, 62.08870764, 66.70489964]\n",
        "s = tuple([x/255 for x in s])\n",
        "s"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.24703223247058823, 0.24348512800000002, 0.26158784172549016)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pENZSYqbvTEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "1160e4d6-cb0f-40b4-fcdd-00588d10200a"
      },
      "source": [
        "!pip install torchtoolbox\n",
        "from torchtoolbox.transform import Cutout"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtoolbox in /usr/local/lib/python3.6/dist-packages (0.1.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.14.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (4.41.1)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (0.99)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtoolbox) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torchtoolbox) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTdIBzpDckY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      \n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomCrop(size=32,padding=1),\n",
        "                                       Cutout(p=0.25,scale=(0.02, 0.10)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=m, std=s)\n",
        "                                       \n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      \n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=m, std=s)\n",
        "                                       ])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9e3d946f-4b8b-464d-af8c-035e2888e5ca"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='../cifar10_data', train=True,\n",
        "                                        download=True, transform=train_transforms)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='../cifar10_data', train=False,\n",
        "                                       download=True, transform=test_transforms)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lCIbOpBhai5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "708b084d-31b8-43b7-8502-07ecd7f5535f"
      },
      "source": [
        "SEED = 101\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "device = \"cuda\"\n",
        "if cuda:\n",
        "    device = \"cuda\"\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "# dataloader arguments\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=2, pin_memory=True) if cuda else dict(shuffle=True, batch_size=4)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnYaVpwfdoO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, **dataloader_args)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, **dataloader_args)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNPCNrQ80CpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-5YPhVr2ADu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwosmxfFb4vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "993ca4e3-3d23-4bf0-a78a-9b1016c89bf0"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "d = {\n",
        "        'misclassified': [],\n",
        "        'train_losses': [],\n",
        "        'test_losses': [],\n",
        "        'train_accuracy': [],\n",
        "        'test_accuracy': []\n",
        "    }\n",
        "\n",
        "total = ['L2+BN'] # , 'GBN', 'L2+GBN'\n",
        "tracker = {}\n",
        "for item in total:\n",
        "    tracker[item] = deepcopy(d)\n",
        "\n",
        "# tracker['L1+BN']['test_accuracy'].append(100)\n",
        "for k, v in tracker.items():\n",
        "    print(k, \">>>>\", v)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2+BN >>>> {'misclassified': [], 'train_losses': [], 'test_losses': [], 'train_accuracy': [], 'test_accuracy': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDYwxf6ldVAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = ResNet18().to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXG4-9CwXFXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0442030-b57e-4ab6-c07f-bc7a8b1a61e9"
      },
      "source": [
        "summary(model2, input_size=(3, 32, 32))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-19          [-1, 128, 16, 16]               0\n",
            "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
            "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
            "       BasicBlock-24          [-1, 128, 16, 16]               0\n",
            "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
            "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-31            [-1, 256, 8, 8]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
            "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
            "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
            "       BasicBlock-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
            "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
            "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
            "           Linear-49                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,173,962\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.25\n",
            "Params size (MB): 42.63\n",
            "Estimated Total Size (MB): 53.89\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g8q89VueRej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0pp8nRzaO-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test(model, device, train_loader, optimizer, epochs, scheduler, test, test_loader, type_, tracker, l1_lambda=None, l2_lambda=None):\n",
        "    if test and not test_loader:\n",
        "        raise ValueError(\"`test`= True but `test_loader` not provided\")\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        l1 = torch.tensor(0, requires_grad=False)\n",
        "        correct = 0\n",
        "        processed = 0\n",
        "        train_loss = 0\n",
        "\n",
        "        print(f\"\\n\\nepoch: {epoch + 1}\")\n",
        "        # pbar = tqdm(train_loader)\n",
        "\n",
        "        if \"l2\" in type_.lower():\n",
        "            optimizer.param_groups[0]['weight_decay'] = l2_lambda\n",
        "            \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, target = data\n",
        "            inputs, target = inputs.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # set the gradients top zero to avoid accumulatin them over the epochs\n",
        "\n",
        "            output = model(inputs)  # model's output\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # if \"l1\" in type_.lower():\n",
        "            #     for param in model.parameters():\n",
        "            #         l1 = l1 + param.abs().sum()\n",
        "            #     loss = loss + l1_lambda * l1.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            processed += len(data)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            if i%100 == 0:\n",
        "              print(f'epoch:{epoch+1}.... batch:{i+1}...loss:{train_loss:.4f}')\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        acc = 100 * correct / processed\n",
        "        tracker[type_]['train_losses'].append(train_loss)\n",
        "        tracker[type_]['train_accuracy'].append(acc)\n",
        "\n",
        "        # pbar.set_description(desc=f'loss={loss.item()} batch_id={batch_idx}')\n",
        "        if scheduler:\n",
        "            print(f'\\n>>>lr: {scheduler.get_last_lr()[0]}')\n",
        "            scheduler.step()\n",
        "        print('\\nTrain set: \\t\\t Accuracy: {}/{} ({:.6f}%)'.format(correct, len(train_loader.dataset),\n",
        "                                                                   100.0 * correct / len(train_loader.dataset)))\n",
        "\n",
        "        if test:\n",
        "            model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    data, target = data.to(device), target.to(device)\n",
        "                    output = model(data)\n",
        "                    test_loss +=criterion(output, target).sum().item()  # sum up batch loss\n",
        "                    pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                    for i in range(len(pred)):\n",
        "                        if pred[i] != target[i]:\n",
        "                            tracker[type_]['misclassified'].append((data[i], pred[i], target[i]))\n",
        "\n",
        "            test_loss /= len(test_loader.dataset)\n",
        "            t_acc = 100.0 * correct / len(test_loader.dataset)\n",
        "            tracker[type_]['test_losses'].append(test_loss)\n",
        "            tracker[type_]['test_accuracy'].append(t_acc)\n",
        "\n",
        "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.6f}%)\\n'.format(\n",
        "                test_loss, correct, len(test_loader.dataset), t_acc))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTqKUZa9a1DZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f91678e-4d83-42eb-b8a2-34e233a5d52c"
      },
      "source": [
        "l1 = None\n",
        "l2 = 8e-4\n",
        "for combo in total:\n",
        "  start = time.perf_counter()\n",
        "  model2 = ResNet18().to(device)\n",
        "\n",
        "  optimizer = optim.SGD(model2.parameters(), lr=0.007, momentum=0.9, nesterov=True)\n",
        "  scheduler = StepLR(optimizer=optimizer, step_size=2, gamma=0.579)\n",
        "\n",
        "  train_test(model2, device, trainloader, optimizer, epochs=20, scheduler=scheduler, test=True, test_loader=testloader,\n",
        "            type_=combo, tracker=tracker, l1_lambda=l1, l2_lambda=l2)\n",
        "  end = time.perf_counter()\n",
        "  print(f\"\\n\\nTime taken for:{combo} = {(end-start)/60:.3f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "epoch: 1\n",
            "epoch:1.... batch:1...loss:2.3969\n",
            "epoch:1.... batch:101...loss:167.6963\n",
            "epoch:1.... batch:201...loss:297.1771\n",
            "epoch:1.... batch:301...loss:408.5744\n",
            "\n",
            ">>>lr: 0.007\n",
            "\n",
            "Train set: \t\t Accuracy: 26944/50000 (53.888000%)\n",
            "\n",
            "Test set: Average loss: 0.0080, Accuracy: 6565/10000 (65.650000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "epoch:2.... batch:1...loss:0.9065\n",
            "epoch:2.... batch:101...loss:85.7947\n",
            "epoch:2.... batch:201...loss:163.8732\n",
            "epoch:2.... batch:301...loss:239.0713\n",
            "\n",
            ">>>lr: 0.007\n",
            "\n",
            "Train set: \t\t Accuracy: 36339/50000 (72.678000%)\n",
            "\n",
            "Test set: Average loss: 0.0056, Accuracy: 7444/10000 (74.440000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "epoch:3.... batch:1...loss:0.5742\n",
            "epoch:3.... batch:101...loss:58.7365\n",
            "epoch:3.... batch:201...loss:115.2808\n",
            "epoch:3.... batch:301...loss:170.8308\n",
            "\n",
            ">>>lr: 0.004053\n",
            "\n",
            "Train set: \t\t Accuracy: 40310/50000 (80.620000%)\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 8012/10000 (80.120000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "epoch:4.... batch:1...loss:0.3196\n",
            "epoch:4.... batch:101...loss:48.9960\n",
            "epoch:4.... batch:201...loss:98.0295\n",
            "epoch:4.... batch:301...loss:146.9356\n",
            "\n",
            ">>>lr: 0.004053\n",
            "\n",
            "Train set: \t\t Accuracy: 41508/50000 (83.016000%)\n",
            "\n",
            "Test set: Average loss: 0.0042, Accuracy: 8169/10000 (81.690000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "epoch:5.... batch:1...loss:0.3823\n",
            "epoch:5.... batch:101...loss:41.7088\n",
            "epoch:5.... batch:201...loss:79.8529\n",
            "epoch:5.... batch:301...loss:118.5553\n",
            "\n",
            ">>>lr: 0.002346687\n",
            "\n",
            "Train set: \t\t Accuracy: 43193/50000 (86.386000%)\n",
            "\n",
            "Test set: Average loss: 0.0036, Accuracy: 8429/10000 (84.290000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "epoch:6.... batch:1...loss:0.2557\n",
            "epoch:6.... batch:101...loss:34.4006\n",
            "epoch:6.... batch:201...loss:68.9511\n",
            "epoch:6.... batch:301...loss:104.5597\n",
            "\n",
            ">>>lr: 0.002346687\n",
            "\n",
            "Train set: \t\t Accuracy: 43961/50000 (87.922000%)\n",
            "\n",
            "Test set: Average loss: 0.0040, Accuracy: 8283/10000 (82.830000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "epoch:7.... batch:1...loss:0.2801\n",
            "epoch:7.... batch:101...loss:28.9014\n",
            "epoch:7.... batch:201...loss:56.8908\n",
            "epoch:7.... batch:301...loss:85.8570\n",
            "\n",
            ">>>lr: 0.001358731773\n",
            "\n",
            "Train set: \t\t Accuracy: 45101/50000 (90.202000%)\n",
            "\n",
            "Test set: Average loss: 0.0032, Accuracy: 8625/10000 (86.250000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "epoch:8.... batch:1...loss:0.2604\n",
            "epoch:8.... batch:101...loss:25.4072\n",
            "epoch:8.... batch:201...loss:52.3761\n",
            "epoch:8.... batch:301...loss:78.0322\n",
            "\n",
            ">>>lr: 0.001358731773\n",
            "\n",
            "Train set: \t\t Accuracy: 45588/50000 (91.176000%)\n",
            "\n",
            "Test set: Average loss: 0.0033, Accuracy: 8631/10000 (86.310000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "epoch:9.... batch:1...loss:0.2462\n",
            "epoch:9.... batch:101...loss:22.3032\n",
            "epoch:9.... batch:201...loss:43.9933\n",
            "epoch:9.... batch:301...loss:65.9001\n",
            "\n",
            ">>>lr: 0.0007867056965669999\n",
            "\n",
            "Train set: \t\t Accuracy: 46325/50000 (92.650000%)\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 8731/10000 (87.310000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "epoch:10.... batch:1...loss:0.1844\n",
            "epoch:10.... batch:101...loss:19.5038\n",
            "epoch:10.... batch:201...loss:40.5208\n",
            "epoch:10.... batch:301...loss:60.5582\n",
            "\n",
            ">>>lr: 0.0007867056965669999\n",
            "\n",
            "Train set: \t\t Accuracy: 46621/50000 (93.242000%)\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 8787/10000 (87.870000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "epoch:11.... batch:1...loss:0.2599\n",
            "epoch:11.... batch:101...loss:17.5332\n",
            "epoch:11.... batch:201...loss:35.8085\n",
            "epoch:11.... batch:301...loss:54.0623\n",
            "\n",
            ">>>lr: 0.00045550259831229293\n",
            "\n",
            "Train set: \t\t Accuracy: 47048/50000 (94.096000%)\n",
            "\n",
            "Test set: Average loss: 0.0030, Accuracy: 8796/10000 (87.960000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "epoch:12.... batch:1...loss:0.1347\n",
            "epoch:12.... batch:101...loss:16.8047\n",
            "epoch:12.... batch:201...loss:33.0101\n",
            "epoch:12.... batch:301...loss:49.5603\n",
            "\n",
            ">>>lr: 0.00045550259831229293\n",
            "\n",
            "Train set: \t\t Accuracy: 47294/50000 (94.588000%)\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8804/10000 (88.040000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "epoch:13.... batch:1...loss:0.1276\n",
            "epoch:13.... batch:101...loss:15.4274\n",
            "epoch:13.... batch:201...loss:30.2418\n",
            "epoch:13.... batch:301...loss:44.7764\n",
            "\n",
            ">>>lr: 0.00026373600442281756\n",
            "\n",
            "Train set: \t\t Accuracy: 47529/50000 (95.058000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8828/10000 (88.280000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "epoch:14.... batch:1...loss:0.2492\n",
            "epoch:14.... batch:101...loss:14.1590\n",
            "epoch:14.... batch:201...loss:28.4503\n",
            "epoch:14.... batch:301...loss:43.0451\n",
            "\n",
            ">>>lr: 0.00026373600442281756\n",
            "\n",
            "Train set: \t\t Accuracy: 47771/50000 (95.542000%)\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8835/10000 (88.350000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "epoch:15.... batch:1...loss:0.1401\n",
            "epoch:15.... batch:101...loss:13.7653\n",
            "epoch:15.... batch:201...loss:27.0942\n",
            "epoch:15.... batch:301...loss:40.3625\n",
            "\n",
            ">>>lr: 0.00015270314656081136\n",
            "\n",
            "Train set: \t\t Accuracy: 47865/50000 (95.730000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8878/10000 (88.780000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "epoch:16.... batch:1...loss:0.1277\n",
            "epoch:16.... batch:101...loss:13.0559\n",
            "epoch:16.... batch:201...loss:26.9846\n",
            "epoch:16.... batch:301...loss:39.7752\n",
            "\n",
            ">>>lr: 0.00015270314656081136\n",
            "\n",
            "Train set: \t\t Accuracy: 47947/50000 (95.894000%)\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 8858/10000 (88.580000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "epoch:17.... batch:1...loss:0.1390\n",
            "epoch:17.... batch:101...loss:12.0074\n",
            "epoch:17.... batch:201...loss:24.4891\n",
            "epoch:17.... batch:301...loss:37.3636\n",
            "\n",
            ">>>lr: 8.841512185870977e-05\n",
            "\n",
            "Train set: \t\t Accuracy: 48076/50000 (96.152000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8869/10000 (88.690000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "epoch:18.... batch:1...loss:0.1101\n",
            "epoch:18.... batch:101...loss:12.3828\n",
            "epoch:18.... batch:201...loss:24.3939\n",
            "epoch:18.... batch:301...loss:36.9674\n",
            "\n",
            ">>>lr: 8.841512185870977e-05\n",
            "\n",
            "Train set: \t\t Accuracy: 48108/50000 (96.216000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8879/10000 (88.790000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "epoch:19.... batch:1...loss:0.1132\n",
            "epoch:19.... batch:101...loss:12.5808\n",
            "epoch:19.... batch:201...loss:24.4155\n",
            "epoch:19.... batch:301...loss:35.9294\n",
            "\n",
            ">>>lr: 5.1192355556192955e-05\n",
            "\n",
            "Train set: \t\t Accuracy: 48153/50000 (96.306000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8875/10000 (88.750000%)\n",
            "\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "epoch:20.... batch:1...loss:0.0693\n",
            "epoch:20.... batch:101...loss:12.3799\n",
            "epoch:20.... batch:201...loss:23.9662\n",
            "epoch:20.... batch:301...loss:35.6788\n",
            "\n",
            ">>>lr: 5.1192355556192955e-05\n",
            "\n",
            "Train set: \t\t Accuracy: 48166/50000 (96.332000%)\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 8883/10000 (88.830000%)\n",
            "\n",
            "\n",
            "\n",
            "Time taken for:L2+BN = 22.029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUjYAmtfeUtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}